{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkasolver as ps\n",
    "from pkasolver import util\n",
    "from pkasolver import analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader\n",
    "import random\n",
    "\n",
    "def mol_to_pyg(prot):\n",
    "    \"\"\"Take protonated molecules and return a Pytorch Geometric Data object.\"\"\"\n",
    "    i = 0\n",
    "    num_atoms = prot.GetNumAtoms()\n",
    "    nodes = []\n",
    "    edges = []\n",
    "    edges_attr = []\n",
    "\n",
    "    for mol in [prot]:\n",
    "\n",
    "        # ComputeGasteigerCharges(mol)\n",
    "\n",
    "        for atom in mol.GetAtoms():\n",
    "            nodes.append(\n",
    "                np.array(\n",
    "                    [\n",
    "                        #atom.GetIdx() + num_atoms * i,\n",
    "                        #float(atom.GetProp(\"_GasteigerCharge\")),\n",
    "                        atom.GetSymbol() == \"C\",\n",
    "                        atom.GetSymbol() == \"O\",\n",
    "                        atom.GetSymbol() == \"N\",\n",
    "                        atom.GetSymbol() == \"P\",\n",
    "                        atom.GetSymbol() == \"F\",\n",
    "                        atom.GetSymbol() == \"Cl\",\n",
    "                        atom.GetSymbol() == \"I\",\n",
    "                        atom.GetFormalCharge(),\n",
    "                        atom.GetChiralTag(),\n",
    "                        atom.GetHybridization(),\n",
    "                        atom.GetNumExplicitHs(),\n",
    "                        atom.GetIsAromatic(),\n",
    "                        atom.GetTotalValence(),\n",
    "                        atom.GetTotalDegree()\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        for bond in mol.GetBonds():\n",
    "            edges.append(\n",
    "                np.array(\n",
    "                    [\n",
    "                        [bond.GetBeginAtomIdx() + num_atoms * i],\n",
    "                        [bond.GetEndAtomIdx() + num_atoms * i],\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "            bond_type = [bond.GetBondTypeAsDouble(), bond.GetIsConjugated()]\n",
    "            edges_attr.append(bond_type)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    X = torch.tensor(np.array([np.array(xi) for xi in nodes]), dtype=torch.float)\n",
    "    edge_index = torch.tensor(np.hstack(np.array(edges)), dtype=torch.long)\n",
    "    edge_attr = torch.tensor(np.array(edges_attr).reshape(-1, 1), dtype=torch.float)\n",
    "\n",
    "    return Data(x=X, edge_index=edge_index, edge_attr=edge_attr).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pKa marvin_pKa marvin_atom marvin_pKa_type original_dataset       ID  \\\n",
      "0  6.21       6.09          10           basic     ['chembl25']  1702768   \n",
      "1  7.46        8.2           9           basic     ['chembl25']   273537   \n",
      "2   4.2       3.94           9           basic  ['datawarrior']     7175   \n",
      "3  3.73       5.91           8          acidic  ['datawarrior']      998   \n",
      "4  11.0       8.94          13           basic     ['chembl25']   560562   \n",
      "\n",
      "                                  smiles  \\\n",
      "0     Brc1c(NC2CC2)nc(C2CC2)nc1N1CCCCCC1   \n",
      "1      Brc1cc(Br)c(NC2=[NH+]CCN2)c(Br)c1   \n",
      "2                 Brc1cc2cccnc2c2ncccc12   \n",
      "3                Brc1ccc(-c2nn[n-]n2)cc1   \n",
      "4  Brc1ccc(Br)c(N(CC2CC2)C2=[NH+]CCN2)c1   \n",
      "\n",
      "                                          protonated  \\\n",
      "0  <img data-content=\"rdkit/molecule\" src=\"data:i...   \n",
      "1  <img data-content=\"rdkit/molecule\" src=\"data:i...   \n",
      "2  <img data-content=\"rdkit/molecule\" src=\"data:i...   \n",
      "3  <img data-content=\"rdkit/molecule\" src=\"data:i...   \n",
      "4  <img data-content=\"rdkit/molecule\" src=\"data:i...   \n",
      "\n",
      "                                        deprotonated            ka  \n",
      "0  <img data-content=\"rdkit/molecule\" src=\"data:i...  6.165950e-07  \n",
      "1  <img data-content=\"rdkit/molecule\" src=\"data:i...  3.467369e-08  \n",
      "2  <img data-content=\"rdkit/molecule\" src=\"data:i...  6.309573e-05  \n",
      "3  <img data-content=\"rdkit/molecule\" src=\"data:i...  1.862087e-04  \n",
      "4  <img data-content=\"rdkit/molecule\" src=\"data:i...  1.000000e-11  \n"
     ]
    }
   ],
   "source": [
    "data_folder_Bal = \"../data/Baltruschat/\"\n",
    "SDFfile1 = data_folder_Bal + \"combined_training_datasets_unique.sdf\"\n",
    "SDFfile2 = data_folder_Bal + \"novartis_cleaned_mono_unique_notraindata.sdf\"\n",
    "SDFfile3 = data_folder_Bal + \"AvLiLuMoVe_cleaned_mono_unique_notraindata.sdf\"\n",
    "# specify device\n",
    "device = 'cpu'\n",
    "#device = 'cuda'\n",
    "\n",
    "df1 = ps.util.import_sdf(SDFfile1)\n",
    "df2 = ps.util.import_sdf(SDFfile2)\n",
    "df3 = ps.util.import_sdf(SDFfile3)\n",
    "\n",
    "#Data corrections:\n",
    "df1.marvin_atom[90] = \"3\"\n",
    "\n",
    "df1 = util.conjugates_to_DataFrame(df1)\n",
    "df1 = util.sort_conjugates(df1)\n",
    "df1 = util.pka_to_ka(df1)\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_attr=[48, 1], edge_index=[2, 24], x=[21, 14], y=[1]) \n",
      "\n",
      " tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 4., 4.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 4., 4.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 4., 4.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 4., 4.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 3., 0., 0., 3., 3.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 4., 4.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 4., 4.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 0., 1., 4., 3.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 0., 1., 4., 3.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 0., 1., 4., 3.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 1., 0., 3., 1., 1., 4., 3.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 0., 1., 4., 3.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 3., 0., 1., 3., 2.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 4., 4.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 4., 4.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 4., 4.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 3., 0., 0., 3., 3.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 4., 4.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 4., 4.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 4., 4.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 1., 1.]]) \n",
      "\n",
      " tensor([[ 0,  1,  2,  3,  4,  5,  4,  7,  8,  9, 10, 11, 11, 13, 14,  9, 16, 17,\n",
      "         18,  8,  6, 12, 15, 19],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "         19, 20,  0,  7, 13, 17]])\n"
     ]
    }
   ],
   "source": [
    "#create pyG Dataset\n",
    "dataset = []\n",
    "for i in range(len(df1.index)):\n",
    "    dataset.append(mol_to_pyg(df1.protonated[i]))\n",
    "    dataset[i].y = torch.tensor([float(df1.pKa[i])], dtype=torch.float32, device=device)\n",
    "print(dataset[0], '\\n\\n' ,dataset[0].x,'\\n\\n', dataset[0].edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_attr=[48, 1], edge_index=[2, 24], x=[21, 14], y=[1]) \n",
      "\n",
      " tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 4., 4.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 4., 4.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 4., 4.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 4., 4.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 3., 0., 0., 3., 3.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 4., 4.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 4., 4.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 0., 1., 4., 3.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 0., 1., 4., 3.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 0., 1., 4., 3.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 1., 0., 3., 1., 1., 4., 3.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 0., 1., 4., 3.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 3., 0., 1., 3., 2.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 4., 4.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 4., 4.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 4., 4.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 3., 0., 0., 3., 3.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 4., 4.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 4., 4.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 4., 4.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 1., 1.]]) \n",
      "\n",
      " tensor([[ 0,  1,  2,  3,  4,  5,  4,  7,  8,  9, 10, 11, 11, 13, 14,  9, 16, 17,\n",
      "         18,  8,  6, 12, 15, 19],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "         19, 20,  0,  7, 13, 17]]) \n",
      "\n",
      " tensor([[1.0000],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.5000],\n",
      "        [1.0000],\n",
      "        [1.5000],\n",
      "        [1.0000],\n",
      "        [1.5000],\n",
      "        [1.0000],\n",
      "        [1.5000],\n",
      "        [1.0000],\n",
      "        [1.5000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.5000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0], '\\n\\n' ,dataset[0].x,'\\n\\n', dataset[0].edge_index,'\\n\\n', dataset[0].edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set Hyperparameters\n",
    "train_test_split = 0.8\n",
    "hidden_channels = 64\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 10000\n",
    "\n",
    "#split train and test set\n",
    "\n",
    "random.shuffle(dataset)\n",
    "\n",
    "split_length=int(len(dataset)*train_test_split)\n",
    "train_dataset = dataset[:split_length]\n",
    "test_dataset = dataset[split_length:]\n",
    "#create Dataloader objects that contain batches \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(14, 96)\n",
      "  (conv2): GCNConv(96, 64)\n",
      "  (conv3): GCNConv(64, 64)\n",
      "  (conv4): GCNConv(64, 64)\n",
      "  (lin): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "Epoch: 010, Train MAE: 1.9780, Test MAE: 2.0561\n",
      "Epoch: 020, Train MAE: 1.8181, Test MAE: 1.8886\n",
      "Epoch: 030, Train MAE: 1.8667, Test MAE: 1.9306\n",
      "Epoch: 040, Train MAE: 1.8128, Test MAE: 1.8844\n",
      "Epoch: 050, Train MAE: 1.8418, Test MAE: 1.8965\n",
      "Epoch: 060, Train MAE: 1.7258, Test MAE: 1.7893\n",
      "Epoch: 070, Train MAE: 1.6721, Test MAE: 1.7428\n",
      "Epoch: 080, Train MAE: 1.6168, Test MAE: 1.6934\n",
      "Epoch: 090, Train MAE: 1.5937, Test MAE: 1.6574\n",
      "Epoch: 100, Train MAE: 1.4651, Test MAE: 1.5344\n",
      "Epoch: 110, Train MAE: 1.4201, Test MAE: 1.4766\n",
      "Epoch: 120, Train MAE: 1.3289, Test MAE: 1.3790\n",
      "Epoch: 130, Train MAE: 1.3594, Test MAE: 1.4054\n",
      "Epoch: 140, Train MAE: 1.3250, Test MAE: 1.3819\n",
      "Epoch: 150, Train MAE: 1.2787, Test MAE: 1.3467\n",
      "Epoch: 160, Train MAE: 1.2515, Test MAE: 1.3123\n",
      "Epoch: 170, Train MAE: 1.2552, Test MAE: 1.3343\n",
      "Epoch: 180, Train MAE: 1.2764, Test MAE: 1.3337\n",
      "Epoch: 190, Train MAE: 1.2715, Test MAE: 1.3435\n",
      "Epoch: 200, Train MAE: 1.1982, Test MAE: 1.2643\n",
      "Epoch: 210, Train MAE: 1.1724, Test MAE: 1.2340\n",
      "Epoch: 220, Train MAE: 1.2106, Test MAE: 1.2751\n",
      "Epoch: 230, Train MAE: 1.1678, Test MAE: 1.2452\n",
      "Epoch: 240, Train MAE: 1.2012, Test MAE: 1.2747\n",
      "Epoch: 250, Train MAE: 1.1559, Test MAE: 1.2413\n",
      "Epoch: 260, Train MAE: 1.1611, Test MAE: 1.2358\n",
      "Epoch: 270, Train MAE: 1.1548, Test MAE: 1.2434\n",
      "Epoch: 280, Train MAE: 1.1359, Test MAE: 1.2398\n",
      "Epoch: 290, Train MAE: 1.1571, Test MAE: 1.2361\n",
      "Epoch: 300, Train MAE: 1.1232, Test MAE: 1.2156\n",
      "Epoch: 310, Train MAE: 1.1148, Test MAE: 1.2271\n",
      "Epoch: 320, Train MAE: 1.1272, Test MAE: 1.2066\n",
      "Epoch: 330, Train MAE: 1.1276, Test MAE: 1.2195\n",
      "Epoch: 340, Train MAE: 1.1149, Test MAE: 1.2272\n",
      "Epoch: 350, Train MAE: 1.1324, Test MAE: 1.2359\n",
      "Epoch: 360, Train MAE: 1.0849, Test MAE: 1.1852\n",
      "Epoch: 370, Train MAE: 1.1317, Test MAE: 1.2314\n",
      "Epoch: 380, Train MAE: 1.0771, Test MAE: 1.1807\n",
      "Epoch: 390, Train MAE: 1.0948, Test MAE: 1.2077\n",
      "Epoch: 400, Train MAE: 1.0849, Test MAE: 1.1945\n",
      "Epoch: 410, Train MAE: 1.0977, Test MAE: 1.2258\n",
      "Epoch: 420, Train MAE: 1.0944, Test MAE: 1.2197\n",
      "Epoch: 430, Train MAE: 1.0547, Test MAE: 1.1953\n",
      "Epoch: 440, Train MAE: 1.1095, Test MAE: 1.2363\n",
      "Epoch: 450, Train MAE: 1.0531, Test MAE: 1.2024\n",
      "Epoch: 460, Train MAE: 1.0631, Test MAE: 1.1874\n",
      "Epoch: 470, Train MAE: 1.0646, Test MAE: 1.1965\n",
      "Epoch: 480, Train MAE: 1.0157, Test MAE: 1.1694\n",
      "Epoch: 490, Train MAE: 1.0519, Test MAE: 1.1912\n",
      "Epoch: 500, Train MAE: 1.0896, Test MAE: 1.2382\n",
      "Epoch: 510, Train MAE: 1.0341, Test MAE: 1.1816\n",
      "Epoch: 520, Train MAE: 1.0282, Test MAE: 1.1699\n",
      "Epoch: 530, Train MAE: 1.0388, Test MAE: 1.1891\n",
      "Epoch: 540, Train MAE: 1.0379, Test MAE: 1.1784\n",
      "Epoch: 550, Train MAE: 1.0711, Test MAE: 1.2370\n",
      "Epoch: 560, Train MAE: 1.0155, Test MAE: 1.1691\n",
      "Epoch: 570, Train MAE: 1.0060, Test MAE: 1.1504\n",
      "Epoch: 580, Train MAE: 1.0359, Test MAE: 1.1798\n",
      "Epoch: 590, Train MAE: 0.9771, Test MAE: 1.1782\n",
      "Epoch: 600, Train MAE: 0.9701, Test MAE: 1.1694\n",
      "Epoch: 610, Train MAE: 1.0105, Test MAE: 1.1644\n",
      "Epoch: 620, Train MAE: 0.9678, Test MAE: 1.1637\n",
      "Epoch: 630, Train MAE: 0.9703, Test MAE: 1.1591\n",
      "Epoch: 640, Train MAE: 0.9819, Test MAE: 1.1627\n",
      "Epoch: 650, Train MAE: 0.9991, Test MAE: 1.1934\n",
      "Epoch: 660, Train MAE: 0.9536, Test MAE: 1.1441\n",
      "Epoch: 670, Train MAE: 0.9898, Test MAE: 1.1651\n",
      "Epoch: 680, Train MAE: 0.9850, Test MAE: 1.1884\n",
      "Epoch: 690, Train MAE: 0.9697, Test MAE: 1.1654\n",
      "Epoch: 700, Train MAE: 0.9687, Test MAE: 1.1599\n",
      "Epoch: 710, Train MAE: 0.9640, Test MAE: 1.1620\n",
      "Epoch: 720, Train MAE: 0.9622, Test MAE: 1.1699\n",
      "Epoch: 730, Train MAE: 0.9769, Test MAE: 1.1839\n",
      "Epoch: 740, Train MAE: 1.0106, Test MAE: 1.1996\n",
      "Epoch: 750, Train MAE: 0.9810, Test MAE: 1.1830\n",
      "Epoch: 760, Train MAE: 0.9770, Test MAE: 1.1909\n",
      "Epoch: 770, Train MAE: 0.9643, Test MAE: 1.1837\n",
      "Epoch: 780, Train MAE: 0.9505, Test MAE: 1.1621\n",
      "Epoch: 790, Train MAE: 0.9659, Test MAE: 1.1879\n",
      "Epoch: 800, Train MAE: 0.9528, Test MAE: 1.1866\n",
      "Epoch: 810, Train MAE: 0.9526, Test MAE: 1.1762\n",
      "Epoch: 820, Train MAE: 0.9619, Test MAE: 1.1817\n",
      "Epoch: 830, Train MAE: 0.9117, Test MAE: 1.1566\n",
      "Epoch: 840, Train MAE: 0.9625, Test MAE: 1.1866\n",
      "Epoch: 850, Train MAE: 0.9315, Test MAE: 1.1585\n",
      "Epoch: 860, Train MAE: 0.9240, Test MAE: 1.1619\n",
      "Epoch: 870, Train MAE: 0.9180, Test MAE: 1.1639\n",
      "Epoch: 880, Train MAE: 0.9579, Test MAE: 1.1998\n",
      "Epoch: 890, Train MAE: 0.9513, Test MAE: 1.1783\n",
      "Epoch: 900, Train MAE: 0.9284, Test MAE: 1.1735\n",
      "Epoch: 910, Train MAE: 1.0140, Test MAE: 1.2408\n",
      "Epoch: 920, Train MAE: 0.9474, Test MAE: 1.1787\n",
      "Epoch: 930, Train MAE: 0.9054, Test MAE: 1.1555\n",
      "Epoch: 940, Train MAE: 0.9391, Test MAE: 1.1589\n",
      "Epoch: 950, Train MAE: 0.9147, Test MAE: 1.1597\n",
      "Epoch: 960, Train MAE: 0.9331, Test MAE: 1.1704\n",
      "Epoch: 970, Train MAE: 0.9001, Test MAE: 1.1638\n",
      "Epoch: 980, Train MAE: 0.8909, Test MAE: 1.1571\n",
      "Epoch: 990, Train MAE: 0.8892, Test MAE: 1.1628\n",
      "Epoch: 1000, Train MAE: 0.8938, Test MAE: 1.1423\n",
      "Epoch: 1010, Train MAE: 0.9101, Test MAE: 1.1604\n",
      "Epoch: 1020, Train MAE: 0.8997, Test MAE: 1.1635\n",
      "Epoch: 1030, Train MAE: 0.9058, Test MAE: 1.1491\n",
      "Epoch: 1040, Train MAE: 0.9012, Test MAE: 1.1764\n",
      "Epoch: 1050, Train MAE: 0.8865, Test MAE: 1.1322\n",
      "Epoch: 1060, Train MAE: 0.9104, Test MAE: 1.1520\n",
      "Epoch: 1070, Train MAE: 0.8842, Test MAE: 1.1403\n",
      "Epoch: 1080, Train MAE: 0.8805, Test MAE: 1.1567\n",
      "Epoch: 1090, Train MAE: 0.8711, Test MAE: 1.1625\n",
      "Epoch: 1100, Train MAE: 0.8845, Test MAE: 1.1396\n",
      "Epoch: 1110, Train MAE: 0.8774, Test MAE: 1.1371\n",
      "Epoch: 1120, Train MAE: 0.8719, Test MAE: 1.1457\n",
      "Epoch: 1130, Train MAE: 0.8750, Test MAE: 1.1223\n",
      "Epoch: 1140, Train MAE: 0.8746, Test MAE: 1.1539\n",
      "Epoch: 1150, Train MAE: 0.8623, Test MAE: 1.1373\n",
      "Epoch: 1160, Train MAE: 0.8450, Test MAE: 1.1297\n",
      "Epoch: 1170, Train MAE: 0.8864, Test MAE: 1.1525\n",
      "Epoch: 1180, Train MAE: 0.8564, Test MAE: 1.1466\n",
      "Epoch: 1190, Train MAE: 0.9106, Test MAE: 1.1676\n",
      "Epoch: 1200, Train MAE: 0.8605, Test MAE: 1.1477\n",
      "Epoch: 1210, Train MAE: 0.8702, Test MAE: 1.1293\n",
      "Epoch: 1220, Train MAE: 0.8521, Test MAE: 1.1312\n",
      "Epoch: 1230, Train MAE: 0.8449, Test MAE: 1.1289\n",
      "Epoch: 1240, Train MAE: 0.8476, Test MAE: 1.1191\n",
      "Epoch: 1250, Train MAE: 0.8873, Test MAE: 1.1403\n",
      "Epoch: 1260, Train MAE: 0.8697, Test MAE: 1.1413\n",
      "Epoch: 1270, Train MAE: 0.8907, Test MAE: 1.1453\n",
      "Epoch: 1280, Train MAE: 0.8850, Test MAE: 1.1632\n",
      "Epoch: 1290, Train MAE: 0.8372, Test MAE: 1.1261\n",
      "Epoch: 1300, Train MAE: 0.8577, Test MAE: 1.1190\n",
      "Epoch: 1310, Train MAE: 0.8803, Test MAE: 1.1514\n",
      "Epoch: 1320, Train MAE: 0.8774, Test MAE: 1.1461\n",
      "Epoch: 1330, Train MAE: 0.8683, Test MAE: 1.1265\n",
      "Epoch: 1340, Train MAE: 0.8530, Test MAE: 1.1289\n",
      "Epoch: 1350, Train MAE: 0.8311, Test MAE: 1.1097\n",
      "Epoch: 1360, Train MAE: 0.8677, Test MAE: 1.1379\n",
      "Epoch: 1370, Train MAE: 0.8357, Test MAE: 1.1016\n",
      "Epoch: 1380, Train MAE: 0.8281, Test MAE: 1.1161\n",
      "Epoch: 1390, Train MAE: 0.8513, Test MAE: 1.1369\n",
      "Epoch: 1400, Train MAE: 0.8315, Test MAE: 1.1240\n",
      "Epoch: 1410, Train MAE: 0.8240, Test MAE: 1.1273\n",
      "Epoch: 1420, Train MAE: 0.8594, Test MAE: 1.1153\n",
      "Epoch: 1430, Train MAE: 0.8751, Test MAE: 1.1386\n",
      "Epoch: 1440, Train MAE: 0.8301, Test MAE: 1.1113\n",
      "Epoch: 1450, Train MAE: 0.8443, Test MAE: 1.1418\n",
      "Epoch: 1460, Train MAE: 0.8315, Test MAE: 1.1201\n",
      "Epoch: 1470, Train MAE: 0.8328, Test MAE: 1.1381\n",
      "Epoch: 1480, Train MAE: 0.8465, Test MAE: 1.1216\n",
      "Epoch: 1490, Train MAE: 0.8097, Test MAE: 1.1111\n",
      "Epoch: 1500, Train MAE: 0.8292, Test MAE: 1.1169\n",
      "Epoch: 1510, Train MAE: 0.8526, Test MAE: 1.1513\n",
      "Epoch: 1520, Train MAE: 0.8172, Test MAE: 1.1063\n",
      "Epoch: 1530, Train MAE: 0.8274, Test MAE: 1.1042\n",
      "Epoch: 1540, Train MAE: 0.8292, Test MAE: 1.1257\n",
      "Epoch: 1550, Train MAE: 0.8416, Test MAE: 1.1227\n",
      "Epoch: 1560, Train MAE: 0.8384, Test MAE: 1.1339\n",
      "Epoch: 1570, Train MAE: 0.8193, Test MAE: 1.1029\n",
      "Epoch: 1580, Train MAE: 0.8106, Test MAE: 1.1273\n",
      "Epoch: 1590, Train MAE: 0.8116, Test MAE: 1.0965\n",
      "Epoch: 1600, Train MAE: 0.8207, Test MAE: 1.1153\n",
      "Epoch: 1610, Train MAE: 0.8254, Test MAE: 1.1144\n",
      "Epoch: 1620, Train MAE: 0.8272, Test MAE: 1.1209\n",
      "Epoch: 1630, Train MAE: 0.8162, Test MAE: 1.1200\n",
      "Epoch: 1640, Train MAE: 0.8363, Test MAE: 1.1050\n",
      "Epoch: 1650, Train MAE: 0.8190, Test MAE: 1.1026\n",
      "Epoch: 1660, Train MAE: 0.8821, Test MAE: 1.1264\n",
      "Epoch: 1670, Train MAE: 0.7839, Test MAE: 1.1140\n",
      "Epoch: 1680, Train MAE: 0.8214, Test MAE: 1.1178\n",
      "Epoch: 1690, Train MAE: 0.8395, Test MAE: 1.1560\n",
      "Epoch: 1700, Train MAE: 0.8071, Test MAE: 1.1228\n",
      "Epoch: 1710, Train MAE: 0.8260, Test MAE: 1.1195\n",
      "Epoch: 1720, Train MAE: 0.7880, Test MAE: 1.1048\n",
      "Epoch: 1730, Train MAE: 0.8223, Test MAE: 1.1242\n",
      "Epoch: 1740, Train MAE: 0.8233, Test MAE: 1.1406\n",
      "Epoch: 1750, Train MAE: 0.7869, Test MAE: 1.1016\n",
      "Epoch: 1760, Train MAE: 0.7993, Test MAE: 1.0975\n",
      "Epoch: 1770, Train MAE: 0.8177, Test MAE: 1.1085\n",
      "Epoch: 1780, Train MAE: 0.7889, Test MAE: 1.0964\n",
      "Epoch: 1790, Train MAE: 0.8121, Test MAE: 1.1180\n",
      "Epoch: 1800, Train MAE: 0.7984, Test MAE: 1.1159\n",
      "Epoch: 1810, Train MAE: 0.7954, Test MAE: 1.1020\n",
      "Epoch: 1820, Train MAE: 0.8009, Test MAE: 1.1142\n",
      "Epoch: 1830, Train MAE: 0.8021, Test MAE: 1.1184\n",
      "Epoch: 1840, Train MAE: 0.8131, Test MAE: 1.1247\n",
      "Epoch: 1850, Train MAE: 0.8598, Test MAE: 1.1588\n",
      "Epoch: 1860, Train MAE: 0.7877, Test MAE: 1.1286\n",
      "Epoch: 1870, Train MAE: 0.7914, Test MAE: 1.0917\n",
      "Epoch: 1880, Train MAE: 0.7914, Test MAE: 1.0993\n",
      "Epoch: 1890, Train MAE: 0.8423, Test MAE: 1.1420\n",
      "Epoch: 1900, Train MAE: 0.8073, Test MAE: 1.1063\n",
      "Epoch: 1910, Train MAE: 0.7883, Test MAE: 1.0953\n",
      "Epoch: 1920, Train MAE: 0.8015, Test MAE: 1.1240\n",
      "Epoch: 1930, Train MAE: 0.7737, Test MAE: 1.1056\n",
      "Epoch: 1940, Train MAE: 0.7971, Test MAE: 1.1129\n",
      "Epoch: 1950, Train MAE: 0.8467, Test MAE: 1.1490\n",
      "Epoch: 1960, Train MAE: 0.7813, Test MAE: 1.1062\n",
      "Epoch: 1970, Train MAE: 0.7930, Test MAE: 1.1067\n",
      "Epoch: 1980, Train MAE: 0.8068, Test MAE: 1.1080\n",
      "Epoch: 1990, Train MAE: 0.8326, Test MAE: 1.1340\n",
      "Epoch: 2000, Train MAE: 0.7806, Test MAE: 1.0978\n",
      "Epoch: 2010, Train MAE: 0.7918, Test MAE: 1.1131\n",
      "Epoch: 2020, Train MAE: 0.8119, Test MAE: 1.1200\n",
      "Epoch: 2030, Train MAE: 0.7671, Test MAE: 1.0957\n",
      "Epoch: 2040, Train MAE: 0.7885, Test MAE: 1.1323\n",
      "Epoch: 2050, Train MAE: 0.7685, Test MAE: 1.0994\n",
      "Epoch: 2060, Train MAE: 0.7965, Test MAE: 1.1079\n",
      "Epoch: 2070, Train MAE: 0.7704, Test MAE: 1.1238\n",
      "Epoch: 2080, Train MAE: 0.8023, Test MAE: 1.1146\n",
      "Epoch: 2090, Train MAE: 0.7907, Test MAE: 1.1020\n",
      "Epoch: 2100, Train MAE: 0.7684, Test MAE: 1.1005\n",
      "Epoch: 2110, Train MAE: 0.7843, Test MAE: 1.0881\n",
      "Epoch: 2120, Train MAE: 0.8305, Test MAE: 1.1189\n",
      "Epoch: 2130, Train MAE: 0.7641, Test MAE: 1.0898\n",
      "Epoch: 2140, Train MAE: 0.7862, Test MAE: 1.1088\n",
      "Epoch: 2150, Train MAE: 0.7826, Test MAE: 1.1070\n",
      "Epoch: 2160, Train MAE: 0.7736, Test MAE: 1.1357\n",
      "Epoch: 2170, Train MAE: 0.8110, Test MAE: 1.1269\n",
      "Epoch: 2180, Train MAE: 0.7826, Test MAE: 1.1117\n",
      "Epoch: 2190, Train MAE: 0.7909, Test MAE: 1.0995\n",
      "Epoch: 2200, Train MAE: 0.7751, Test MAE: 1.1008\n",
      "Epoch: 2210, Train MAE: 0.7770, Test MAE: 1.1147\n",
      "Epoch: 2220, Train MAE: 0.7732, Test MAE: 1.1099\n",
      "Epoch: 2230, Train MAE: 0.7801, Test MAE: 1.0985\n",
      "Epoch: 2240, Train MAE: 0.7845, Test MAE: 1.1261\n",
      "Epoch: 2250, Train MAE: 0.7662, Test MAE: 1.0980\n",
      "Epoch: 2260, Train MAE: 0.7657, Test MAE: 1.1166\n",
      "Epoch: 2270, Train MAE: 0.7487, Test MAE: 1.0969\n",
      "Epoch: 2280, Train MAE: 0.7670, Test MAE: 1.1126\n",
      "Epoch: 2290, Train MAE: 0.7822, Test MAE: 1.1062\n",
      "Epoch: 2300, Train MAE: 0.7603, Test MAE: 1.1106\n",
      "Epoch: 2310, Train MAE: 0.7699, Test MAE: 1.1086\n",
      "Epoch: 2320, Train MAE: 0.7957, Test MAE: 1.1291\n",
      "Epoch: 2330, Train MAE: 0.7674, Test MAE: 1.1287\n",
      "Epoch: 2340, Train MAE: 0.7678, Test MAE: 1.0924\n",
      "Epoch: 2350, Train MAE: 0.7596, Test MAE: 1.0962\n",
      "Epoch: 2360, Train MAE: 0.7757, Test MAE: 1.1278\n",
      "Epoch: 2370, Train MAE: 0.7762, Test MAE: 1.1086\n",
      "Epoch: 2380, Train MAE: 0.7562, Test MAE: 1.0991\n",
      "Epoch: 2390, Train MAE: 0.7510, Test MAE: 1.1115\n",
      "Epoch: 2400, Train MAE: 0.7838, Test MAE: 1.1087\n",
      "Epoch: 2410, Train MAE: 0.7630, Test MAE: 1.1210\n",
      "Epoch: 2420, Train MAE: 0.7888, Test MAE: 1.1460\n",
      "Epoch: 2430, Train MAE: 0.7755, Test MAE: 1.1256\n",
      "Epoch: 2440, Train MAE: 0.7463, Test MAE: 1.0833\n",
      "Epoch: 2450, Train MAE: 0.7800, Test MAE: 1.1257\n",
      "Epoch: 2460, Train MAE: 0.7362, Test MAE: 1.1068\n",
      "Epoch: 2470, Train MAE: 0.7793, Test MAE: 1.1080\n",
      "Epoch: 2480, Train MAE: 0.7655, Test MAE: 1.1115\n",
      "Epoch: 2490, Train MAE: 0.7363, Test MAE: 1.0930\n",
      "Epoch: 2500, Train MAE: 0.7815, Test MAE: 1.1272\n",
      "Epoch: 2510, Train MAE: 0.7518, Test MAE: 1.1048\n",
      "Epoch: 2520, Train MAE: 0.7388, Test MAE: 1.1138\n",
      "Epoch: 2530, Train MAE: 0.7336, Test MAE: 1.1055\n",
      "Epoch: 2540, Train MAE: 0.7432, Test MAE: 1.0955\n",
      "Epoch: 2550, Train MAE: 0.7538, Test MAE: 1.1121\n",
      "Epoch: 2560, Train MAE: 0.7375, Test MAE: 1.1195\n",
      "Epoch: 2570, Train MAE: 0.7495, Test MAE: 1.1119\n",
      "Epoch: 2580, Train MAE: 0.7439, Test MAE: 1.0930\n",
      "Epoch: 2590, Train MAE: 0.7272, Test MAE: 1.1041\n",
      "Epoch: 2600, Train MAE: 0.7770, Test MAE: 1.1010\n",
      "Epoch: 2610, Train MAE: 0.7740, Test MAE: 1.1122\n",
      "Epoch: 2620, Train MAE: 0.7527, Test MAE: 1.1113\n",
      "Epoch: 2630, Train MAE: 0.7493, Test MAE: 1.0889\n",
      "Epoch: 2640, Train MAE: 0.7668, Test MAE: 1.1186\n",
      "Epoch: 2650, Train MAE: 0.7499, Test MAE: 1.0992\n",
      "Epoch: 2660, Train MAE: 0.7546, Test MAE: 1.1081\n",
      "Epoch: 2670, Train MAE: 0.7568, Test MAE: 1.1058\n",
      "Epoch: 2680, Train MAE: 0.7215, Test MAE: 1.0883\n",
      "Epoch: 2690, Train MAE: 0.7977, Test MAE: 1.1410\n",
      "Epoch: 2700, Train MAE: 0.7407, Test MAE: 1.1195\n",
      "Epoch: 2710, Train MAE: 0.7745, Test MAE: 1.1148\n",
      "Epoch: 2720, Train MAE: 0.7428, Test MAE: 1.0993\n",
      "Epoch: 2730, Train MAE: 0.7364, Test MAE: 1.1082\n",
      "Epoch: 2740, Train MAE: 0.7262, Test MAE: 1.1088\n",
      "Epoch: 2750, Train MAE: 0.7459, Test MAE: 1.1011\n",
      "Epoch: 2760, Train MAE: 0.7572, Test MAE: 1.1043\n",
      "Epoch: 2770, Train MAE: 0.7457, Test MAE: 1.1151\n",
      "Epoch: 2780, Train MAE: 0.7145, Test MAE: 1.0993\n",
      "Epoch: 2790, Train MAE: 0.7178, Test MAE: 1.1020\n",
      "Epoch: 2800, Train MAE: 0.7608, Test MAE: 1.1119\n",
      "Epoch: 2810, Train MAE: 0.7957, Test MAE: 1.1498\n",
      "Epoch: 2820, Train MAE: 0.7371, Test MAE: 1.1022\n",
      "Epoch: 2830, Train MAE: 0.7368, Test MAE: 1.1020\n",
      "Epoch: 2840, Train MAE: 0.7677, Test MAE: 1.1155\n",
      "Epoch: 2850, Train MAE: 0.7556, Test MAE: 1.1052\n",
      "Epoch: 2860, Train MAE: 0.7251, Test MAE: 1.1024\n",
      "Epoch: 2870, Train MAE: 0.7344, Test MAE: 1.1053\n",
      "Epoch: 2880, Train MAE: 0.7484, Test MAE: 1.1021\n",
      "Epoch: 2890, Train MAE: 0.7190, Test MAE: 1.0871\n",
      "Epoch: 2900, Train MAE: 0.7495, Test MAE: 1.1204\n",
      "Epoch: 2910, Train MAE: 0.8020, Test MAE: 1.1578\n",
      "Epoch: 2920, Train MAE: 0.7575, Test MAE: 1.0962\n",
      "Epoch: 2930, Train MAE: 0.7110, Test MAE: 1.0956\n",
      "Epoch: 2940, Train MAE: 0.7334, Test MAE: 1.1030\n",
      "Epoch: 2950, Train MAE: 0.7240, Test MAE: 1.1146\n",
      "Epoch: 2960, Train MAE: 0.7346, Test MAE: 1.1022\n",
      "Epoch: 2970, Train MAE: 0.7144, Test MAE: 1.0775\n",
      "Epoch: 2980, Train MAE: 0.7724, Test MAE: 1.1183\n",
      "Epoch: 2990, Train MAE: 0.7270, Test MAE: 1.1011\n",
      "Epoch: 3000, Train MAE: 0.7596, Test MAE: 1.1098\n",
      "Epoch: 3010, Train MAE: 0.7180, Test MAE: 1.0957\n",
      "Epoch: 3020, Train MAE: 0.7382, Test MAE: 1.1345\n",
      "Epoch: 3030, Train MAE: 0.7332, Test MAE: 1.0871\n",
      "Epoch: 3040, Train MAE: 0.7195, Test MAE: 1.0966\n",
      "Epoch: 3050, Train MAE: 0.7427, Test MAE: 1.1098\n",
      "Epoch: 3060, Train MAE: 0.7360, Test MAE: 1.0893\n",
      "Epoch: 3070, Train MAE: 0.7287, Test MAE: 1.1089\n",
      "Epoch: 3080, Train MAE: 0.7432, Test MAE: 1.1095\n",
      "Epoch: 3090, Train MAE: 0.7448, Test MAE: 1.0887\n",
      "Epoch: 3100, Train MAE: 0.7601, Test MAE: 1.0996\n",
      "Epoch: 3110, Train MAE: 0.7219, Test MAE: 1.1000\n",
      "Epoch: 3120, Train MAE: 0.7399, Test MAE: 1.1025\n",
      "Epoch: 3130, Train MAE: 0.7084, Test MAE: 1.1084\n",
      "Epoch: 3140, Train MAE: 0.7361, Test MAE: 1.1085\n",
      "Epoch: 3150, Train MAE: 0.7108, Test MAE: 1.1009\n",
      "Epoch: 3160, Train MAE: 0.7167, Test MAE: 1.1097\n",
      "Epoch: 3170, Train MAE: 0.7303, Test MAE: 1.1264\n",
      "Epoch: 3180, Train MAE: 0.7037, Test MAE: 1.1069\n",
      "Epoch: 3190, Train MAE: 0.7439, Test MAE: 1.1130\n",
      "Epoch: 3200, Train MAE: 0.7038, Test MAE: 1.1181\n",
      "Epoch: 3210, Train MAE: 0.7172, Test MAE: 1.0999\n",
      "Epoch: 3220, Train MAE: 0.6997, Test MAE: 1.0952\n",
      "Epoch: 3230, Train MAE: 0.7241, Test MAE: 1.1048\n",
      "Epoch: 3240, Train MAE: 0.7249, Test MAE: 1.0987\n",
      "Epoch: 3250, Train MAE: 0.6970, Test MAE: 1.0908\n",
      "Epoch: 3260, Train MAE: 0.7241, Test MAE: 1.0991\n",
      "Epoch: 3270, Train MAE: 0.7201, Test MAE: 1.0869\n",
      "Epoch: 3280, Train MAE: 0.7012, Test MAE: 1.1010\n",
      "Epoch: 3290, Train MAE: 0.6885, Test MAE: 1.0947\n",
      "Epoch: 3300, Train MAE: 0.7226, Test MAE: 1.1158\n",
      "Epoch: 3310, Train MAE: 0.7232, Test MAE: 1.0955\n",
      "Epoch: 3320, Train MAE: 0.6866, Test MAE: 1.0910\n",
      "Epoch: 3330, Train MAE: 0.7205, Test MAE: 1.0805\n",
      "Epoch: 3340, Train MAE: 0.7412, Test MAE: 1.0981\n",
      "Epoch: 3350, Train MAE: 0.7154, Test MAE: 1.1080\n",
      "Epoch: 3360, Train MAE: 0.7309, Test MAE: 1.0977\n",
      "Epoch: 3370, Train MAE: 0.7078, Test MAE: 1.0820\n",
      "Epoch: 3380, Train MAE: 0.7171, Test MAE: 1.0913\n",
      "Epoch: 3390, Train MAE: 0.7044, Test MAE: 1.0792\n",
      "Epoch: 3400, Train MAE: 0.7142, Test MAE: 1.0889\n",
      "Epoch: 3410, Train MAE: 0.7329, Test MAE: 1.0995\n",
      "Epoch: 3420, Train MAE: 0.7601, Test MAE: 1.0988\n",
      "Epoch: 3430, Train MAE: 0.7241, Test MAE: 1.0998\n",
      "Epoch: 3440, Train MAE: 0.6937, Test MAE: 1.0948\n",
      "Epoch: 3450, Train MAE: 0.7172, Test MAE: 1.1007\n",
      "Epoch: 3460, Train MAE: 0.6985, Test MAE: 1.0951\n",
      "Epoch: 3470, Train MAE: 0.7235, Test MAE: 1.1089\n",
      "Epoch: 3480, Train MAE: 0.7234, Test MAE: 1.1043\n",
      "Epoch: 3490, Train MAE: 0.7093, Test MAE: 1.1018\n",
      "Epoch: 3500, Train MAE: 0.7299, Test MAE: 1.1337\n",
      "Epoch: 3510, Train MAE: 0.7439, Test MAE: 1.0992\n",
      "Epoch: 3520, Train MAE: 0.7235, Test MAE: 1.0951\n",
      "Epoch: 3530, Train MAE: 0.7156, Test MAE: 1.1135\n",
      "Epoch: 3540, Train MAE: 0.7246, Test MAE: 1.1086\n",
      "Epoch: 3550, Train MAE: 0.6993, Test MAE: 1.0967\n",
      "Epoch: 3560, Train MAE: 0.7055, Test MAE: 1.0992\n",
      "Epoch: 3570, Train MAE: 0.7149, Test MAE: 1.1049\n",
      "Epoch: 3580, Train MAE: 0.7081, Test MAE: 1.1007\n",
      "Epoch: 3590, Train MAE: 0.7209, Test MAE: 1.0974\n",
      "Epoch: 3600, Train MAE: 0.7282, Test MAE: 1.1117\n",
      "Epoch: 3610, Train MAE: 0.7150, Test MAE: 1.1165\n",
      "Epoch: 3620, Train MAE: 0.7552, Test MAE: 1.1288\n",
      "Epoch: 3630, Train MAE: 0.7205, Test MAE: 1.1042\n",
      "Epoch: 3640, Train MAE: 0.7170, Test MAE: 1.1117\n",
      "Epoch: 3650, Train MAE: 0.7307, Test MAE: 1.1148\n",
      "Epoch: 3660, Train MAE: 0.7283, Test MAE: 1.1125\n",
      "Epoch: 3670, Train MAE: 0.7365, Test MAE: 1.1232\n",
      "Epoch: 3680, Train MAE: 0.7198, Test MAE: 1.0838\n",
      "Epoch: 3690, Train MAE: 0.7166, Test MAE: 1.1283\n",
      "Epoch: 3700, Train MAE: 0.7311, Test MAE: 1.0972\n",
      "Epoch: 3710, Train MAE: 0.7313, Test MAE: 1.1060\n",
      "Epoch: 3720, Train MAE: 0.6894, Test MAE: 1.1115\n",
      "Epoch: 3730, Train MAE: 0.7188, Test MAE: 1.1046\n",
      "Epoch: 3740, Train MAE: 0.6959, Test MAE: 1.1039\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import NNConv\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.nn import global_max_pool\n",
    "from torch_geometric.nn import global_add_pool\n",
    "from torch import optim\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(1)\n",
    "        self.conv1 = GCNConv(dataset[0].num_node_features, 96)\n",
    "        self.conv2 = GCNConv(96, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv4 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = x.relu()\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=hidden_channels).to(device=device)\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.MSELoss()\n",
    "criterion_v = torch.nn.L1Loss() # that's the MAE Loss\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "def train(loader):\n",
    "    model.train()\n",
    "    for data in loader:  # Iterate in batches over the training dataset.\n",
    "        out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        loss = criterion(out.flatten(), data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    loss = torch.Tensor([0]).to(device=device)\n",
    "    for data in loader:  # Iterate in batches over the training dataset.\n",
    "        out = model(data.x, data.edge_index, data.batch) \n",
    "        loss += criterion_v(out.flatten(), data.y)\n",
    "    return loss/len(loader) # MAE loss of batches can be summed and divided by the number of batches\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train(train_loader)\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Train MAE: {train_acc.item():.4f}, Test MAE: {test_acc.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
